# DevOps Concepts & AWS CodePipeline Implementation with Spring Boot Application

### Overview

This document provides detailed information on the DevOps procedures, along with brief descriptions of AWS Services & SonarCloud. The final section is an in-depth overview of start to finish, how to deploy a Spring Boot Application to AWS CodePipeline. Please expand each section for more details. 

<details>
<summary style="font-size: 24px;">DevOps and Agile</summary>

Agile is a mentality or philosophy utilized when approaching the creation of information systems, and is a flexible approach of addressing the steps of the Software Development Life Cycle. Development teams who practice an Agile methodology place a focus on producing code through iteration and collaboration rather than following a rigid plan.

At first glance, DevOps and Agile may seem contradictory; DevOps involves the creation of a systematic approach to producing code while Agile is a mentality that focuses on creating products by adapting to change quickly. However, the goal of both methodologies is to produce working and valuable product more efficiently. DevOps pertains to the entire system working together to produce, test, deploy and maintain the code base, while Agile practices allow for each step of that process to change wherever and whenever needed.
* Agile Practices with DevOps:
  * Continuous Integration
  * Continuous Delivery
  * Continuous Deployment

Adoption of the Agile philosophies can provide a stepping stone for the establishment of a working DevOps pipeline, as Agile practices intrinsically produce more continuous feedback loops. Continuous Integration, Continuous Delivery and Continuous Deployment seek to automate the phases of DevOps as much as possible.

![](https://wac-cdn.atlassian.com/dam/jcr:aa29a13c-67a8-424b-a21b-ad10fe6897df/DevOps%20infinity%20wheel_SIMPLE.png?cdnVersion=484)

## Continuous Integration
Continuous Integration (CI) is the first, and most fundamental step in creating an autonomous development pipeline.

Similarly to Continuous Delivery and Continuous Deployment, Continuous Integration is a development team mentality, and is achieved when all members of the development team practice consistent merging of code into a central repository. For CI to take place, these Central repositories should be in the form of version control software.

Version control software is a tool which utilizes some directory structure to store files. These tools can track changes to code, and allow for changes to be merged (allowing you to select which changes to keep or reject if/when conflicts arise) or files to be rolled back to a previous version. The integration of code into these repositories should happen as often as possible with at least one commit each day. Generally, the more frequently code is merged, the less conflicts and/or integration issues will arise.

The best way to ensure your code integrates well is to marry the integration of your code with testing the code. Running test suites on the code base after new commits helps to minimize potential disruptions if conflicts do arise, particularly when utilizing certain DevOps tools to automatically run unit and integration tests. 

## Continuous Delivery
Continuous Delivery is a paradigm in which the building, management and testing of produced software is automated such that deployments can be performed at the push of a button.

Continuous delivery is often confused with Continuous Deployment, which automates the entire production pipeline, including deployment. Continuous Delivery; however is the process of automating all steps of a Development pipeline except for the final deployment step. Inherently, Continuous Delivery is dependent on the implementation of Continuous Integration, and also serves as a stepping stone to creating a fully automated Development Pipeline (Continuous Deployment). Though Continuous Integration can technically be achieved without automation, Continuous Delivery is only achieved when code integration, testing and product building has been automated. In this way, you are able to perform frequent deployments "at the press of a button", but may choose not to do so, usually for business purposes or possibly due to a preference for a regular scheduled deployment process.

The deployment to production may also be kept manual so that final user acceptance tests can be performed manually as a final safety check on the code to ensure that it meets business needs. This is due to the difficulty and cost of creating tests to evaluate the user experience and not simply the functionality.

## Continuous Deployment
Continuous Deployment is a process of releasing software in which changes are tested for stability and correctness automatically. This results in immediate, autonomous deployment of code to production environments.

Continuous Deployment is often confused with Continuous Delivery due to nomenclature as both are referred to as 'CD'; however, Continuous Delivery is simply a precursor to Continuous Deployment. In Continuous Delivery there is a final, manual approval process needed before code is deployed to production environments. Continuous Deployment forgoes human intervention at every step of the deployment process, and pushes new code into the working production environment immediately so long as it meets the test requirements. When Continuous Deployment is achieved, every committed change to the code base creates and deploys a new build to the production environment.

Continuous Deployment is the ultimate goal for establishing a true DevOps pipeline, as it ensures that all steps for the creation of product, including code creation, testing, building, and deployment are automated and work seamlessly together.

As the major difference for Continuous Deployment and Delivery resides in the manual approval of deploying code to production, many benefits (feedback speed, code quality and efficiency) are retained with the use of Continuous Deployment. However, there are some additional considerations for Continuous Deployment:
- With Continuous Deployment, there is no chance to perform manual tests before deploying to production, since the entire pipeline is automated.
</details>
<details>
<summary style="font-size: 24px;">Benefits of DevOps</summary> 

-   **Speed**
    -   Teams that practice DevOps release deliverables more frequently, with higher quality and stability.
    -   A Report found that elite teams deploy 208 times more frequently and 106 times faster than low-performing teams.
    -   Continuous delivery allows teams to build, test, and deliver software with automated tools.
-   **Improved Collaboration**
    -   culture of collaboration between developers and operations teams, who share responsibilities and combine work.
    -   This makes teams more efficient and saves time related to work handoffs and creating code that is designed for the environment where it runs.
-   **Rapid Deployment**
    -   teams improve products rapidly.
    -   A competitive advantage can be gained by quickly releasing new features and repairing bugs.
-   **Quality and reliability**
    -   Practices like continuous integration and continuous delivery ensure changes are functional and safe, which improves the quality of a software product.
    -   Monitoring helps teams keep informed of performance in real-time.
-   **Security**
    -   By integrating security into a continuous integration, continuous delivery, and continuous deployment pipeline, DevSecOps is an active, integrated part of the development process.
    -   Security is built into the product by integrating active security audits and security testing into agile development and DevOps workflows.

</details>
<details>
<summary style="font-size: 24px;">AWS Services</summary> 

-   **CodeBuild**
    -   AWS Fully managed continuous integration service that compiles source code, runs tests, and produces software packages that are ready to deploy
    -   donâ€™t need to provision, manage, and scale your own build servers
    -   scales continuously and processes multiple builds concurrently, so your builds are not left waiting in a queue.
    -   you are charged by the minute for the compute resources you use when building. (Free tier = 100 min/month)
-   **CodePipeline**
    -   AWS Fully managed continuous delivery service that helps you automate your release pipelines for fast and reliable application and infrastructure updates.
    -   automates the build, test, and deploy phases of your release process every time there is a code change
    -   Enables you to rapidly and reliably deliver features and updates
    -   You can easily integrate AWS CodePipeline with third-party services such as GitHub.
    -   You only pay for what you use. There are no upfront fees or long-term commitments.
-   **CodeDeploy**
    -   AWS Fully managed deployment service that automates software deployments to a variety of compute services such as - AWS Elastic Beanstalk- Amazon EC2 - AWS Fargate - AWS Lambda - on-premises servers
    -   Makes it easier for you to rapidly release new features
    -   helps you avoid downtime during application deployment
    -   handles the complexity of updating your applications
        - **Elastic Beanstalk**
            - We plan to use this deployment method as it's the simplist to implment with our application
            - Using just a .jar file of our built application we can deploy our application in just a few minutes after every commit to `main`
            - This leverages an ec2 instance for us with some pre-built configuration of the virtual machine to include java & maven by default, allowing us to execute out jar file with ease.
            - ***IMPORTANT*** Elastic Beanstalk by default looks for all applications to expose PORT 5000, so make sure within your `application.yml` or `application.properties` the PORT is assigned to 5000.
-   **CloudWatch**
    -   CloudWatch monitors your Amazon Web Services (AWS) resources and the applications you run on AWS in real time
    -   Automatically displays metrics about every AWS service in use, allowing you to collect and track metrics to evaluate your applications resources.
    - Alarms can be generated to watch metrics and automatically send notifications
        -   Everyone uses CloudWatch when the deploy their free tier RDS instance, along with any other free tier service, as there is a default CloudWatch alarm placed to track monthly usage. 
        -   For RDS, towards the end of each month you should receive an email when you've used ~75% of your free tier if you're database has 100% uptime. 
    -   These are extraordinarily helpful in the preventation of over provisioning cloud resources to prevent unintentially charges to your AWS account. 

    ![](https://docs.aws.amazon.com/images/AmazonCloudWatch/latest/monitoring/images/CW-Overview.png)

</details>
<details>

<summary style="font-size: 24px;">SonarCloud</summary> 

## SonarCloud

SonarCloud is a cloud-based code quality, security and review tool by signing up for free at [sonarcloud.io](https://sonarcloud.io/explore/projects). This supports up to 23 languages, including Java, Javascript and Typescript. This is a free-open source analysis tool for all of your publicly accessible projects to help align the team with a shared definition of clean code.
- NOTE: Be mindful that these are public and stored on sonarcloud, meaning you must make sure to obfuscate any sensitive information from your GitHub repository.
</details>
<details>
<summary style="font-size: 24px;">Implementation of CodePipeline with Spring Boot</summary> 

# Implementation

We will go over the steps involved in deploying a Spring Boot Appliation to CodePipeline, please fork the following repository and follow the below procedures for practice. [FORK THIS GITHUB REPO!](https://github.com/JesterCharles/bootPipeline.git)

After you've forked this repository, we can begin with the first steps of deployment. Before heading to AWS CodePipeline you must first create an Elastic Beanstalk application for the Deploy Stage. We do this first to make the creation of our pipeline seamless, but the Deploy Stage can always be configured and edited later if need be.

1. Generate an AWS Elastic Beanstalk Application
First, we head over to `Elastic Beanstalk` by searching for the service in the top search bar. Where we will select the `Create Environment` button in the top right.

- We will then be directed to the `Configure Environment` section of Elastic Beanstalk where we must edit a few sections.
    - **Application Information**
        - Here we will add our application name with the syntax as follows: lastNameApplicationName Example: jesterBootPipeline
    - **Platform**
        - Click the dropdown underneath `Platform` and make sure to select `Java`
        - ***IMPORTANT***: Change the `Platform branch` dropdown to make the Java version your application is using, default is `Correto 17`. 
            - For this `bootPipeline` example application, you would change to `Correto 8`.
    - No more changes necessary. Confirm the material matches the below image and proceed to click the `Next`.
    
        ![](https://i.imgur.com/fhDYwvt.png)
        
- Next we must configure service access to our application. Select the `Create an use new Service role` option underneath `Service role`.
    - Here's were we might need to jump over to IAM roles, as you may or may not have an `EC2 Instance profile` that can be leveraged by Elastic Beanstalk. **Please check the dropdown to confirm. If you do, great, select it and you can skip over the follow steps by selecting `Skip to Review`**:
        1. Very recent changes to AWS have prevented the automatic generation of this role. [Click the link to head to IAM in another tab](https://us-east-1.console.aws.amazon.com/iamv2/home?region=us-east-2#/roles) if your `EC2 Instance Profile` contained no values.
        2. At this page, please click the `Create role` button on the top right. We should be directed to the `Select Trusted Entity` step of the process.
        3. We must now select underneath `Use Cases` the `EC2` bullet. After selection, click `Next` button in bottom right.
        4. In the Search bar with `Filter policies by property...`, please search for **WebTier**. This will have a single result of `AWSElasticBeanstalkWebTier` that you must select the check mark to the left of the name. Click the `Next` button in bottom right.
        5. Finally, all we need to do is add the following text to our `Role name` underneath the `Role Details`. Please name this service role as **aws-elasticbeanstalk-ec2-role**
        6. In the bottom right, Click on `Create Role` button. We can now return to CodePipeline tab, clicking the refresh button to the right of our `EC2 Instance Profile` and our role should now be selectable. Please select this role.
- If you didn't need the `IAM role` for ec2 instance, make sure to check with the Image below that the information matches. Once confirmed, click the `Skip to Review` button and the bottom right. 

    ![](https://i.imgur.com/q16IiMe.png)

- At the Review, check all values matching the image below:

    ![](https://i.imgur.com/9XZcmsr.png)

- After confirming all information matches, scroll down to click submit. The Elastic Beanstalk environment should now being to deploy. This will have a default application, that will later be replace with our Spring Boot app through AWS CodePipeline.

2. Create a new pipeline by once again using the search bar to navigate to `CodePipeline`. here we will begin by selecting `Create Pipeline`.

## Source Stage (CodeCommit w/ GitHub)
- We will be directed to `Choose Pipeline Settings`. Here we must simply edit the `Pipeline name` field with the following syntax: lastNameApplicationName, for example, jesterBootPipeline. Nothing else needs to be changed, everything else is automatically generated. Click `Next`.
- Next, we are prompted to select our `Source provider`, aka where our code base is. This would be GitHub, after selecting the dropdown choose the option `GitHub (Version 2)`, this allows us to connect our AWS account with our GitHub account as follows:
    1. Click the `Connect to Github` button to the right of the `Connection` field. A popup will be generated where we can establish a connection to github.
    2. Specify the `Connection Name`, such as *aws-github-JesterCharles* but can be named whatever you like. Now select `Connect to Github`.
    3. Select `Install New Apps`, where you will be redirected to GitHub to allow permissions to your github account. Follow the default propmts there to establish this connection and you will be redirected back.
    4. Finally, click `Connect`. That connection will now be filled out within the Connection field.
- Next, we will move on to select our `Repository Name`. Since we've established our connection to GitHub we can now select the source code we wish to deploy. In this scenario, that would be `bootPipeline` for those of you that forked the repository. Go ahead and search for `bootPipeline` and select it.
- `Branch Name` is where our trigger will take place to integrate the code onto AWS and by default you should just select the `main` branch. Optionally, if you have a development pipeline you can choose a dev branch as a trigger.
- After this, proceed to click `Next` as no other changes required and can proceed with the build stage.

## Build Stage (CodeBuild)
- For `Build provider`, select `AWS CodeBuild`. This should then pop up additional fields, such as `Region` and `Project Name`.
- Double check that the `Region` is what you or your team has specified as the Region location for use during this project.
- Next, we have to create a `CodeBuild` project. To the right of the `Project name` input field is a `Create Project` button. Please select this button and a popup should appear. Follow the steps below in the new window:
    1. Underneath the `Project configuration` section, in the `Project name` add the name of the project, for example: *jesterBootPipeline*
    2. Underneath the `Environment` section, select the dropdown for `Operating system` and select the `Amazon Linux 2` value.
    3. Next, we must select the appropriate `Runtime` field, which is a default `Standard` there should be no other options.
    4. Underneath the `Image` field select the appropriate image version for default configurations with Java. This would be the `aws/codebuild/amazonlinux2-x86_64-standard:corretto8` for Java 8 specifically. If you're using Java 17, make sure to select the image ending with `standard:4.0` or greater.
- We may not continue on to the `Buildspec` section, here we will select the `Build specifications` as `Insert build commands`. This will store a buildspec.yaml file on the project instead of in our repository. This is useful as some sensitive information can be located in this file.
- Once `Insert build commands` is selected a field `Build commands` will open, select the button to the right of this field for `Switch to editor`.
    - Select all (ctrl+a) within the editor and delete all the default yaml code. 
    - Copy and paste the following block of code below into that editor

    ```yaml
    version: 0.2

    phases:
      install:
        runtime-version:
          java: coretto8 #Note the Java Runtime and change accordingly
      build:
        commands:
          - echo Build started on `date`
          - mvn package
      post_build:
        commands:
          - mv target/*.jar app.jar
    artifacts:
      files:
        - app.jar
    ```
- Once completed your build spec should be as follows:

    ![](https://i.imgur.com/vEako5o.png)

- Confirm the remaining information matches to the image below:

    ![](https://i.imgur.com/UrBfiCP.png)

- Once all information is confirmed, scroll to the bottom and click on the `Continue to CodePipeline`. This will automatically close the popup and update the `Project name` field to match accordingly to the new project. 
- Before moving on to the deploy stage, we must include our Database environment variables to allow our application to build according and obfuscate the sensitive information.
    1. Click the `Add environment variable` button three times for the fields required by our database: DB_URL, DB_USER, DB_PASS
    2. Name the variables and assign the values as follows for this example project: (Name : Value)
        - DB_URL : jdbc:h2:mem:mydb
        - DB_USER : sa
        - DB_PASS : password
    3. Once these three environment varaibles have been set check the following image to make sure it matches:

        ![](https://i.imgur.com/F0KVbnu.png)

    4. **IMPORTANT** You're Spring Boot `application.yaml` or `application.properties` file must access these environment variables on CodeBuild by following this syntax in your file: {VARIABLE_NAME_IN_CODEBUILD} 
        ```yaml
        # Here is an example of CodeBuild Environment variables used for the url, username and password.
        server:
          port: 5000

        spring:
          application:
            name: bootPipeline-api
          datasource:
            driver-class-name: org.h2.Driver
            url: {DB_URL}
            username: {DB_USER}
            password: {DB_PASS}

          jpa:
            database-platform: org.hibernate.dialect.H2Dialect
            show-sql: true
            hibernate:
              ddl-auto: create-drop
        ```
- Once all information has been confirmed, you may now click `Next` to proceed onto the deploy stage

3. Deploy our application to `Elastic Beanstalk`

## Deploy Stage

- Select the dropdown under `Deploy Provider`, where you will see `AWS Elastic Beanstalk` as an option. Select this.
- Next check the `Region` is corrrect. Note, an incorrect region will not show any Elastic Beanstalk applications as they are deployed to specific regions.
- Now select the `Application name` that fits to your Elastic Beanstalk application, for this example that is *jesterBootPipeline*
- Follow this by selecting the `Environment name`, which should format as LastNameApplicationName-env. For this example that would be *JesterBootPipeline-env*
- Confirm all the information and proceed to the next step by clicking `Next`.

4. Review!
- Take a few extra seconds and review that all the information matches accordingly to you application and looks similar to the below image:

    ![](https://i.imgur.com/Wojb71t.png)

5. After Confirmation in previous step, you may now finally click `Create pipeline` button in the bottom right. This may take a few seconds, but you should be directed to the pipeline in execution. Now wait with bated-breath as with DevOps there can always be complications. 
- If any issues arise with the Pipeline, make sure to check any of the logs for any failure in execution of our Spring Boot Application.
- If you cannot parse out what went wrong in a log, make sure to reach out to a trainer for additional assitance.

</details>
